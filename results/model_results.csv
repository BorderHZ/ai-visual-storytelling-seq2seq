num_samples,duration,num_epochs,loss,val_loss,num_layers,cell_type,activation,hidden_dimension,learning_rate,gradient_clipping_value,optimizer,loss_history_filename,model_filename,reverse_sequence,notes
200775,47:24:15h,150,0.195949491072,7.784921676,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-01-29_00:37:26.csv,./trained_models/2018-01-29_00:37:26-2018-01-31_00:01:42.h5,True, all samples are shuflled on every epoch
200775,30:00:00h,100,0.2139,None,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-01_16:22:39.csv,./trained_models/2018-02-01_16:22:39-2018-02-03_00:22:15.h5,False, Added reccurence dropout of 0.2
200775,16:15:28h,50,2.00876955564,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-03_14:00:00.csv,./trained_models/2018-02-03_14:00:00-2018-02-04_06:15:29.h5,False, Input dropout of 0.5
200775,35:23:15h,110,1.47597208434,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-04_10:27:57.csv,./trained_models/2018-02-04_10:27:57-2018-02-05_21:51:13.h5,False, Input dropout of 0.5
200775,13:00:00h,50,1.844,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-07_13:55:01.csv,./trained_models/2018-02-07_13:55:01-2018-02-08_03:15:08,False, dropout: input image and before softmax of 0.5, sending last 3 images. Very good results
200775,19:22:45h,50,0.823522208953,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-08_16:58:54.csv,./trained_models/2018-02-08_16:58:54-2018-02-09_12:21:40.h5,False, Sending the previous sentence with one additional encoder, last_k =3. Overfit for 50 epochs
200775,9:34:01h,25,1.70632990266,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-09_15:30:08.csv,./trained_models/2018-02-09_15:30:08-2018-02-10_01:04:10.h5,False, Sending the previous sentence with one additional encoder, last_k =3.
200775,12:52:40h,50,1.86891705098,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-12_15:36:20.csv,./trained_models/2018-02-12_15:36:20-2018-02-13_04:29:01.h5,False,dropout: input image and before softmax of 0.5, sending last 2 images. Very good results
200775,7:10:37h,19,1.76664380121,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-14_14:33:04.csv,./trained_models/2018-02-14_14:33:04-2018-02-14_21:43:42.h5,False,dropout: input image and before softmax of 0.3, last_k=3, recurrent_dropout = 0.3
200775,11:12:32h,30,1.01023810202,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-15_10:48:00.csv,./trained_models/2018-02-15_10:48:00-2018-02-15_22:00:32.h5,False,
200775,8:18:24h,25,1.65418497207,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-22_17:31:22.csv,./trained_models/2018-02-22_17:31:22-2018-02-23_01:49:46.h5,False,
200775,7:04:44h,25,2.33397364972,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-26_15:53:55.csv,./trained_models/2018-02-26_15:53:55-2018-02-26_22:58:39.h5,False,
200775,14:11:17h,50,1.51347275298,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-02-27_11:57:40.csv,./trained_models/2018-02-27_11:57:40-2018-02-28_02:08:58.h5,False,
200775,3:36:54h,25,3.1871183399720087,-1,2,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-03-27_16:12:18.csv,./trained_models/2018-03-27_16:12:18-2018-03-27_19:49:12.h5,False,
200775,6:52:48h,50,2.751071253554371,-1,2,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-03-28_09:40:22.csv,./trained_models/2018-03-28_09:40:22-2018-03-28_16:33:10.h5,False,
200775,10:42:54h,75,2.3877165697710763,-1,2,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-03-29_10:03:13.csv,./trained_models/2018-03-29_10:03:13-2018-03-29_20:46:07.h5,False,
200775,12:48:56h,50,1.8220028932951646,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-04-04_15:17:54.csv,./trained_models/2018-04-04_15:17:54-2018-04-05_04:06:50.h5,False, k = 4
200775,12:10:32h,50,1.8105872630093318,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-04-05_13:41:29.csv,./trained_models/2018-04-05_13:41:29-2018-04-06_01:52:01.h5,False, k = 5
200775,9:39:43h,25,1.1409408756929886,-1,2,lstm,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-04-17_17:33:41.csv,./trained_models/2018-04-17_17:33:41-2018-04-18_03:13:25.h5,False,
200775,2:37:06h,25,2.8040424125159817,-1,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-04-27_18:03:39.csv,./trained_models/2018-04-27_18:03:39-2018-04-27_20:40:45.h5,False,
200775,11:40:38h,75,1.1825940505013401,-1,1,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-04-30_08:56:33.csv,./trained_models/2018-04-30_08:56:33-2018-04-30_20:37:12.h5,False,
200775,6:41:35h,29,1.7404225285182986,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-05-04_09:49:32.csv,./trained_models/2018-05-04_09:49:32-2018-05-04_16:31:07.h5,False,
200775,2:58:09h,29,2.953462605386724,-1,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-05-09_17:39:11.csv,./trained_models/2018-05-09_17:39:11-2018-05-09_20:37:21.h5,False,
200775,8:11:34h,50,1.4810305310162524,-1,1,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-05-10_09:56:42.csv,./trained_models/2018-05-10_09:56:42-2018-05-10_18:08:17.h5,False,
200775,0:10:56h,1,5.031448554505804,-1,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-19_15-15-24.csv,./trained_models/2018-06-19_15-15-24-2018-06-19_15-26-20.h5,False, k=3, Bahdanau attention
200775,0:36:05h,5,4.192412987106868,4.140798881823171,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-20_11-06-43.csv,./trained_models/2018-06-20_11-06-43-2018-06-20_11-42-49.h5,False,
200775,1:11:31h,10,3.9636364949950393,3.9768016947056344,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-20_12-37-38.csv,./trained_models/2018-06-20_12-37-38-2018-06-20_13-49-10.h5,False,
200775,1:46:19h,15,3.7187253526251336,3.883421925170149,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-20_16-03-44.csv,./trained_models/2018-06-20_16-03-44-2018-06-20_17-50-04.h5,False,
200775,2:12:46h,20,3.585716340307607,3.8373791194392113,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-20_17-56-06.csv,./trained_models/2018-06-20_17-56-06-2018-06-20_20-08-52.h5,False,
200775,3:31:10h,30,3.4180000811225226,3.8339717974882563,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-21_10-56-15.csv,./trained_models/2018-06-21_10-56-15-2018-06-21_14-27-25.h5,False,
200775,5:40:25h,50,3.1469522541686437,3.93953046736593,1,gru,tanh,512,0.0001,5.0,adam,./loss_logs/2018-06-21_16-21-14.csv,./trained_models/2018-06-21_16-21-14-2018-06-21_22-01-40.h5,False,
200775,18:37:32h,50,0.18837449719178218,7.286305555599725,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-06-22_14-16-02.csv,./trained_models/2018-06-22_14-16-02-2018-06-23_08-53-35.h5,False,
200775,10:10:04h,27,1.0647620913353317,5.172195285594535,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-02_12-34-45.csv,./trained_models/2018-07-02_12-34-45-2018-07-02_22-44-50.h5,False,
200775,8:22:33h,22,1.5139503505544338,4.579971986065408,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-03_12-20-27.csv,./trained_models/2018-07-03_12-20-27-2018-07-03_20-43-00.h5,False,
200775,10:05:37h,27,2.0240613790485247,4.061411784884925,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-04_01-30-32.csv,./trained_models/2018-07-04_01-30-32-2018-07-04_11-36-10.h5,False,
200775,12:42:28h,35,1.937381300105652,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-04_13-45-35.csv,./trained_models/2018-07-04_13-45-35-2018-07-05_02-28-03.h5,False,
200775,8:05:26h,50,1.6507643043557017,4.738153244259363,1,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-05_11-58-28.csv,./trained_models/2018-07-05_11-58-28-2018-07-05_20-03-55.h5,False,
200775,11:31:46h,50,0.9843649424097634,-1,2,gru,tanh,1024,0.0001,5.0,adam,./loss_logs/2018-07-07_09-02-55.csv,./trained_models/2018-07-07_09-02-55-2018-07-07_20-34-41.h5,False,
